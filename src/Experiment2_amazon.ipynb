{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from skift import FirstColFtClassifier\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Marek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "# Download stopwords dictionary\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 78450202\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "        Sentiment                                      SentimentText\n0               0  defective: i was really excited to get the fis...\n1               1  m-audio 2496 sound card: excellent sound card ...\n2               0  missing links: it's a shame the quality of thi...\n3               0  tribute album: this is a tribute album...i did...\n4               1  pretty good: it does taste pretty good and is ...\n...           ...                                                ...\n999995          1  tlc...... need i say more: tlc is the best gro...\n999996          1  alternative ending: an excellent book no doubt...\n999997          1  p-town series: i read these out of order becau...\n999998          0  pretty sad....: this book would play out bette...\n999999          1  awesome funky jazz band, definetly check them ...\n\n[1000000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>defective: i was really excited to get the fis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>m-audio 2496 sound card: excellent sound card ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>missing links: it's a shame the quality of thi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>tribute album: this is a tribute album...i did...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>pretty good: it does taste pretty good and is ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999995</th>\n      <td>1</td>\n      <td>tlc...... need i say more: tlc is the best gro...</td>\n    </tr>\n    <tr>\n      <th>999996</th>\n      <td>1</td>\n      <td>alternative ending: an excellent book no doubt...</td>\n    </tr>\n    <tr>\n      <th>999997</th>\n      <td>1</td>\n      <td>p-town series: i read these out of order becau...</td>\n    </tr>\n    <tr>\n      <th>999998</th>\n      <td>0</td>\n      <td>pretty sad....: this book would play out bette...</td>\n    </tr>\n    <tr>\n      <th>999999</th>\n      <td>1</td>\n      <td>awesome funky jazz band, definetly check them ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "# train data\n",
    "data_train = pd.read_csv('../data/AmazonTrainSet1M.tsv', sep='\\t', header=0, encoding=\"utf-8\")\n",
    "data_train['SentimentText'] = data_train['SentimentText'].str.lower()\n",
    "row_sizes = data_train['SentimentText'].str.split().str.len()\n",
    "print(f\"Words count: {pd.Series.sum(row_sizes)}\")\n",
    "data_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 31369658\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "        Sentiment                                      SentimentText\n0               1  this is a great book: i must preface this by s...\n1               0  huge disappointment.: as a big time, long term...\n2               1  wayne is tight but cant hang with turk.: this ...\n3               1  excellent: i read this book when i was in elem...\n4               0  not about anusara: although this book is toute...\n...           ...                                                ...\n399995          0  you can fool all the people some of the time b...\n399996          0  it was good but not good: it was an 'okay' boo...\n399997          0  unwatchable: the product arrived promptly and ...\n399998          0  not worth the money or the time to read.: the ...\n399999          1  a nice shift into a gifted mind with multiple ...\n\n[400000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>this is a great book: i must preface this by s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>huge disappointment.: as a big time, long term...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>wayne is tight but cant hang with turk.: this ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>excellent: i read this book when i was in elem...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>not about anusara: although this book is toute...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>399995</th>\n      <td>0</td>\n      <td>you can fool all the people some of the time b...</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>0</td>\n      <td>it was good but not good: it was an 'okay' boo...</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>0</td>\n      <td>unwatchable: the product arrived promptly and ...</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>0</td>\n      <td>not worth the money or the time to read.: the ...</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>1</td>\n      <td>a nice shift into a gifted mind with multiple ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "# test data\n",
    "data_test = pd.read_csv('../data/AmazonTestSet400k2.tsv', sep='\\t', header=0, encoding=\"utf-8\")\n",
    "data_test['SentimentText'] = data_test['SentimentText'].str.lower()\n",
    "row_sizes = data_test['SentimentText'].str.split().str.len()\n",
    "print(f\"Words count: {pd.Series.sum(row_sizes)}\")\n",
    "data_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\")) \n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = [word for word in text.split() if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_train(df_train, df_test, functions, word_ngrams=1):\n",
    "    _data_train = pd.DataFrame(df_train['SentimentText'])\n",
    "    _data_test = pd.DataFrame(df_test['SentimentText'])\n",
    "    for function in functions:\n",
    "        _data_train['SentimentText'] = _data_train['SentimentText'].apply(lambda x: function(x))\n",
    "        _data_test['SentimentText'] = _data_test['SentimentText'].apply(lambda x: function(x))\n",
    "    _row_sizes = _data_train['SentimentText'].str.split().str.len()\n",
    "    print(f\"Words count: {pd.Series.sum(_row_sizes)}\")\n",
    "    print(_data_train)\n",
    "    _sk_clf = FirstColFtClassifier(wordNgrams=word_ngrams, thread=1)  # lr=0.3, epoch=10\n",
    "    _sk_clf.fit(_data_train[['SentimentText']], df_train['Sentiment'])\n",
    "    _score = _sk_clf.score(_data_test[['SentimentText']], df_test['Sentiment'])\n",
    "    print(f\"Words ngrams: {word_ngrams}\")\n",
    "    return _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 41817156\n",
      "                                            SentimentText\n",
      "0       defective: really excited get fisher-price ama...\n",
      "1       m-audio 2496 sound card: excellent sound card ...\n",
      "2       missing links: shame quality video poor. movie...\n",
      "3       tribute album: tribute album...i pay close eno...\n",
      "4       pretty good: taste pretty good filling staying...\n",
      "...                                                   ...\n",
      "999995  tlc...... need say more: tlc best group ever w...\n",
      "999996  alternative ending: excellent book doubt. go r...\n",
      "999997  p-town series: read order know series. loved r...\n",
      "999998  pretty sad....: book would play better movie s...\n",
      "999999  awesome funky jazz band, definetly check out: ...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.89961"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "score = preprocess_train(data_train, data_test, [remove_stop_words])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 78154408\n",
      "                                            SentimentText\n",
      "0       defective i was really excited to get the fish...\n",
      "1       maudio 2496 sound card excellent sound card fo...\n",
      "2       missing links its a shame the quality of this ...\n",
      "3       tribute album this is a tribute albumi didnt p...\n",
      "4       pretty good it does taste pretty good and is f...\n",
      "...                                                   ...\n",
      "999995  tlc need i say more tlc is the best group ther...\n",
      "999996  alternative ending an excellent book no doubt ...\n",
      "999997  ptown series i read these out of order because...\n",
      "999998  pretty sad this book would play out better on ...\n",
      "999999  awesome funky jazz band definetly check them o...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.9068575"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "score = preprocess_train(data_train, data_test, [remove_punctuation])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 79272968\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "        Sentiment                                      SentimentText\n0               0  defective: i be really excite to get the fishe...\n1               1  m-audio 2496 sound card: excellent sound card ...\n2               0  miss links: it a shame the quality of this vid...\n3               0  tribute album: this be a tribute album i do+no...\n4               1  pretty good: it do taste pretty good and be fi...\n...           ...                                                ...\n999995          1  tlc need i say more: tlc be the best group the...\n999996          1  alternative ending: a excellent book no doubt ...\n999997          1  p-town series: i read these out of order becau...\n999998          0  pretty sad : this book would play out better o...\n999999          1  awesome funky jazz band definetly check them o...\n\n[1000000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>defective: i be really excite to get the fishe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>m-audio 2496 sound card: excellent sound card ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>miss links: it a shame the quality of this vid...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>tribute album: this be a tribute album i do+no...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>pretty good: it do taste pretty good and be fi...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999995</th>\n      <td>1</td>\n      <td>tlc need i say more: tlc be the best group the...</td>\n    </tr>\n    <tr>\n      <th>999996</th>\n      <td>1</td>\n      <td>alternative ending: a excellent book no doubt ...</td>\n    </tr>\n    <tr>\n      <th>999997</th>\n      <td>1</td>\n      <td>p-town series: i read these out of order becau...</td>\n    </tr>\n    <tr>\n      <th>999998</th>\n      <td>0</td>\n      <td>pretty sad : this book would play out better o...</td>\n    </tr>\n    <tr>\n      <th>999999</th>\n      <td>1</td>\n      <td>awesome funky jazz band definetly check them o...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "# train data\n",
    "data_train_lem = pd.read_csv('../data/AmazonTrainLemmatized.tsv', sep='\\t', header=0, encoding=\"utf-8\")\n",
    "row_sizes = data_train_lem['SentimentText'].str.split().str.len()\n",
    "print(f\"Words count: {pd.Series.sum(row_sizes)}\")\n",
    "data_train_lem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 31698635\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "        Sentiment                                      SentimentText\n0               1  this be a great book: i must preface this by s...\n1               0  huge disappointment : as a big time long term ...\n2               1  wayne be tight but cant hang with turk : this ...\n3               1  excellent: i read this book when i be in eleme...\n4               0  not about anusara: although this book be tout ...\n...           ...                                                ...\n399995          0  you can fool all the people some of the time b...\n399996          0  it be good but not good: it be a 'okay' book i...\n399997          0  unwatchable: the product arrive promptly and b...\n399998          0  not worth the money or the time to read : the ...\n399999          1  a nice shift into a gifted mind with multiple ...\n\n[400000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>this be a great book: i must preface this by s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>huge disappointment : as a big time long term ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>wayne be tight but cant hang with turk : this ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>excellent: i read this book when i be in eleme...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>not about anusara: although this book be tout ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>399995</th>\n      <td>0</td>\n      <td>you can fool all the people some of the time b...</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>0</td>\n      <td>it be good but not good: it be a 'okay' book i...</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>0</td>\n      <td>unwatchable: the product arrive promptly and b...</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>0</td>\n      <td>not worth the money or the time to read : the ...</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>1</td>\n      <td>a nice shift into a gifted mind with multiple ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "# test data\n",
    "data_test_lem = pd.read_csv('../data/AmazonTestLemmatized.tsv', sep='\\t', header=0, encoding=\"utf-8\")\n",
    "row_sizes = data_test_lem['SentimentText'].str.split().str.len()\n",
    "print(f\"Words count: {pd.Series.sum(row_sizes)}\")\n",
    "data_test_lem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 79272968\n",
      "                                            SentimentText\n",
      "0       defective: i be really excite to get the fishe...\n",
      "1       m-audio 2496 sound card: excellent sound card ...\n",
      "2       miss links: it a shame the quality of this vid...\n",
      "3       tribute album: this be a tribute album i do+no...\n",
      "4       pretty good: it do taste pretty good and be fi...\n",
      "...                                                   ...\n",
      "999995  tlc need i say more: tlc be the best group the...\n",
      "999996  alternative ending: a excellent book no doubt ...\n",
      "999997  p-town series: i read these out of order becau...\n",
      "999998  pretty sad : this book would play out better o...\n",
      "999999  awesome funky jazz band definetly check them o...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.9030475"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "score = preprocess_train(data_train_lem, data_test_lem, [])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words AND remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 41521362\n",
      "                                            SentimentText\n",
      "0       defective really excited get fisherprice amazi...\n",
      "1       maudio 2496 sound card excellent sound card co...\n",
      "2       missing links shame quality video poor movie f...\n",
      "3       tribute album tribute albumi pay close enough ...\n",
      "4       pretty good taste pretty good filling staying ...\n",
      "...                                                   ...\n",
      "999995  tlc need say more tlc best group ever waz ever...\n",
      "999996  alternative ending excellent book doubt go rob...\n",
      "999997  ptown series read order know series loved rere...\n",
      "999998  pretty sad book would play better movie screen...\n",
      "999999  awesome funky jazz band definetly check out tr...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.89808"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "score = preprocess_train(data_train, data_test, [remove_stop_words, remove_punctuation])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words AND Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 41408983\n",
      "                                            SentimentText\n",
      "0       defective: really excite get fisher-price amaz...\n",
      "1       m-audio 2496 sound card: excellent sound card ...\n",
      "2       miss links: shame quality video poor movie fas...\n",
      "3       tribute album: tribute album do+not pay close ...\n",
      "4       pretty good: taste pretty good fill stay away ...\n",
      "...                                                   ...\n",
      "999995  tlc need say more: tlc best group ever waz eve...\n",
      "999996  alternative ending: excellent book doubt go ro...\n",
      "999997  p-town series: read order do+not know series l...\n",
      "999998  pretty sad : book would play better movie scre...\n",
      "999999  awesome funky jazz band definetly check out: t...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.89564"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "score = preprocess_train(data_train_lem, data_test_lem, [remove_stop_words])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## N-GRAMS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Words count: 78450202\n",
      "                                            SentimentText\n",
      "0       defective: i was really excited to get the fis...\n",
      "1       m-audio 2496 sound card: excellent sound card ...\n",
      "2       missing links: it's a shame the quality of thi...\n",
      "3       tribute album: this is a tribute album...i did...\n",
      "4       pretty good: it does taste pretty good and is ...\n",
      "...                                                   ...\n",
      "999995  tlc...... need i say more: tlc is the best gro...\n",
      "999996  alternative ending: an excellent book no doubt...\n",
      "999997  p-town series: i read these out of order becau...\n",
      "999998  pretty sad....: this book would play out bette...\n",
      "999999  awesome funky jazz band, definetly check them ...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 1\n",
      "0.9085275\n",
      "Words count: 78450202\n",
      "                                            SentimentText\n",
      "0       defective: i was really excited to get the fis...\n",
      "1       m-audio 2496 sound card: excellent sound card ...\n",
      "2       missing links: it's a shame the quality of thi...\n",
      "3       tribute album: this is a tribute album...i did...\n",
      "4       pretty good: it does taste pretty good and is ...\n",
      "...                                                   ...\n",
      "999995  tlc...... need i say more: tlc is the best gro...\n",
      "999996  alternative ending: an excellent book no doubt...\n",
      "999997  p-town series: i read these out of order becau...\n",
      "999998  pretty sad....: this book would play out bette...\n",
      "999999  awesome funky jazz band, definetly check them ...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 2\n",
      "0.93145\n",
      "Words count: 78450202\n",
      "                                            SentimentText\n",
      "0       defective: i was really excited to get the fis...\n",
      "1       m-audio 2496 sound card: excellent sound card ...\n",
      "2       missing links: it's a shame the quality of thi...\n",
      "3       tribute album: this is a tribute album...i did...\n",
      "4       pretty good: it does taste pretty good and is ...\n",
      "...                                                   ...\n",
      "999995  tlc...... need i say more: tlc is the best gro...\n",
      "999996  alternative ending: an excellent book no doubt...\n",
      "999997  p-town series: i read these out of order becau...\n",
      "999998  pretty sad....: this book would play out bette...\n",
      "999999  awesome funky jazz band, definetly check them ...\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "Words ngrams: 3\n",
      "0.9327625\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range(1, 4):  # word_ngrams\n",
    "    score = preprocess_train(data_train, data_test, [], word_ngrams=i)\n",
    "    print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}